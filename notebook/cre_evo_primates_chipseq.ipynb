{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook for manuscript\n",
    "# Trizzino, Park et al (2016)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Following scripts or their modified versions are used for ChIP-seq data processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ChIP-seq processing  \n",
    "An average of 16 lanes per sample  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%writefile 'run_fastqc_macs.py'\n",
    "\n",
    "#!/usr/env/python\n",
    "\n",
    "###\n",
    "# YoSon\n",
    "# usage: python run_fastqc_macs.py [samplelist.txt]\n",
    "###\n",
    "\n",
    "import os, subprocess, sys\n",
    "\n",
    "wkdir = \"primates/chipseq/\"\n",
    "scriptdir = wkdir + 'script/'\n",
    "logdir = wkdir + 'logfiles/'\n",
    "    \n",
    "# make directories for the project\n",
    "    \n",
    "try:\n",
    "    os.makedirs(wkdir)\n",
    "except OSError:\n",
    "    if not os.path.isdir(wkdir):\n",
    "        raise\n",
    "    \n",
    "try:\n",
    "    os.makedirs(scriptdir)\n",
    "except OSError:\n",
    "    if not os.path.isdir(scriptdir):\n",
    "        raise\n",
    "    \n",
    "try:\n",
    "    os.makedirs(logdir)\n",
    "except OSError:\n",
    "    if not os.path.isdir(logdir):\n",
    "        raise\n",
    "\n",
    "\n",
    "def mastercall(i):\n",
    "     \n",
    "    # write header for the job. adjust as necessary\n",
    "    # for lsf scheduler\n",
    "    \n",
    "    master = scriptdir + str(i) + \".fastqc.macs.bsub\"\n",
    "    masterhandle=open(master, 'w')\n",
    "    masterlist = []\n",
    "\n",
    "    bsubfile = scriptdir + str(i) + \".fastqc.macs.bsub.sh\"\n",
    "    \n",
    "    header=r\"\"\"#!/bin/bash\n",
    "#BSUB -J %s.fdr5.fastqc.macs.bsub\n",
    "#BSUB -o primates/chipseq/logfiles/%s.fdr1.fastqc.macs.bsub.o \n",
    "#BSUB -e primates/chipseq/logfiles/%s.fdr1.fastqc.macs.bsub.e\n",
    "#BSUB -n 8\n",
    "#BSUB -R \"span[ptile=8]\"\n",
    "#BSUB -M 50000\n",
    "#BSUB -W 24:00\n",
    "\n",
    "\"\"\"%(i, i, i)\n",
    "\n",
    "    masterlist.append(header)\n",
    "    for x in masterlist:\n",
    "        masterhandle.write(x)\n",
    "    masterhandle.write(\"sh \" + bsubfile + \" \\n\")\n",
    "    masterhandle.close()\n",
    "\n",
    "\n",
    "def bsubcall(i, fq1, fq2, fq3, ref, tfq1, tfq2, tfq3, out1, out2, out3, chref):\n",
    "\n",
    "    bsubfile = scriptdir + str(i) + \".fastqc.macs.bsub.sh\"\n",
    "    bsubhandle=open(bsubfile, 'w')\n",
    "    bsublist = []\n",
    "    \n",
    "    # write script to submit\n",
    "    \n",
    "    bsubbatch=\"\"\"#!/bin/bash\n",
    "\n",
    "wkdir=primates/chipseq\n",
    "sample='%s'\n",
    "fq1=${wkdir}/fastq/test_pool/untrimmed/%s\n",
    "fq2=${wkdir}/fastq/test_pool/untrimmed/%s\n",
    "fq3=${wkdir}/fastq/test_pool/untrimmed/%s\n",
    "#reference genome\n",
    "ref=genomes/%s\n",
    "tfqout=${wkdir}fastq/trimming_outputs/\n",
    "tfq1='%s'\n",
    "tfq2='%s'\n",
    "tfq3='%s'\n",
    "#h3k27ac\n",
    "out1='%s'\n",
    "#h3k4me1\n",
    "out2='%s'\n",
    "#input\n",
    "out3='%s'\n",
    "#reference chrom sizes\n",
    "ref=chromosome_sizes/%s\n",
    "fqout=primates/chipseq/fastq/fastqc_outputs\n",
    "\n",
    "#---------------------------------------------------\n",
    "# log all sample files and params passed\n",
    "\n",
    "echo ${sample}\n",
    "echo ${fq1} # Read 27ac fastq\n",
    "echo ${fq2} # Read me1 fastq\n",
    "echo ${fq3} # Read input fastq\n",
    "echo ${ref} # reference genome\n",
    "echo ${tfq1} # Trimmed 27ac fastq\n",
    "echo ${tfq2} # Trimmed me1 fastq\n",
    "echo ${tfq3} # Trimmed input fastq\n",
    "echo ${out1} # Sample 27ac output name\n",
    "echo ${out2} # Sample me1 output name\n",
    "echo ${out3} # Sample input output name\n",
    "echo ${chref} # chromosomes size\n",
    "\n",
    "#---------------------------------------------------\n",
    "# mkdir in case non-existent\n",
    "\n",
    "mkdir -p ${wkdir}/fastq/test_pool/untrimmed/ \n",
    "mkdir -p ${wkdir}/fastq/trimming_outputs/ \n",
    "mkdir -p ${wkdir}/fastq/fastqc_outputs/\n",
    "\n",
    "#---------------------------------------------------\n",
    "# software used\n",
    "\n",
    "FASTQC=\"bin/local/fastqc\"\n",
    "TRIM=\"bin/local/trim_galore\"\n",
    "CUTADAPT=\"bin/local/cutadapt\"\n",
    "BWA=\"bin/local/bwa\"\n",
    "#new samtools for sort, etc\n",
    "SAMTOOLS1=\"bin/local/samtools\"\n",
    "#new samtools did not inherit functions such as rmdup, flagstats. path to an old version\n",
    "SAMTOOLS2=\"/opt/software/samtools/samtools-0.1.19/samtools\"\n",
    "\n",
    "#---------------------------------------------------\n",
    "# qc\n",
    "${FASTQC} ${fq1} ${fq2} ${fq3} -o ${fqout}\n",
    "\n",
    "#---------------------------------------------------\n",
    "# trimming adapters\n",
    "\n",
    "# 27ac\n",
    "${TRIM} --path_to_cutadapt ${CUTADAPT} -stringency 5 -length 35 -o ${tfqout} -q 20 ${fq1}\n",
    "\n",
    "# me1\n",
    "${TRIM} --path_to_cutadapt ${CUTADAPT} -stringency 5 -length 35 -o ${tfqout} -q 20 ${fq2}\n",
    "\n",
    "# input\n",
    "${TRIM} --path_to_cutadapt ${CUTADAPT} -stringency 5 -length 35 -o ${tfqout} -q 20 ${fq3}\n",
    "\n",
    "\n",
    "#---------------------------------------------------\n",
    "# bwa alignment\n",
    "\n",
    "# processing 27ac samples\n",
    "\n",
    "###\n",
    "#bwa-mem alignment\n",
    "\n",
    "#bwa-mem alignment using 6 threads for all lanes (~average 16 lanes per sample)\n",
    "${BWA} mem -t 6 ${ref} ${tfq1} | ${SAMTOOLS2} view -Sb - > ${out1}_mem.bam\n",
    "\n",
    "# sort\n",
    "${SAMTOOLS2} sort -@ 8 -T ${out1}_mem.bam -O bam -o ${out1}_mem_srt.bam  \n",
    "\n",
    "#merge\n",
    "${SAMTOOLS2} merge -f -@ 8 ${out1}_mgd_mem_sorted.bam *_mem_*.bam\n",
    "\n",
    "# remove dups\n",
    "${SAMTOOLS2} rmdup -s ${out1}_mgd_mem_sorted.bam ${out1}_mgd_mem_sorted_rmdup.bam\n",
    "\n",
    "#THE FOLLOWING COMMANDS RUN THE MAIN STATS FOR THE ALN SEQUENCES BEFORE AND AFTER REMOVING PCR DUPLICATES\n",
    "${SAMTOOLS2} flagstat ${out1}_mgd_mem_sorted.bam > ${out1}_mgd_mem_sorted_stats.txt \n",
    "${SAMTOOLS2} flagstat ${out1}_mgd_mem_sorted_rmdup.bam > ${out1}_mgd_mem_sorted_rmdup_stats.txt\n",
    "\n",
    "\n",
    "#---\n",
    "\n",
    "# processing me1 samples\n",
    "\n",
    "###\n",
    "#bwa-mem alignment\n",
    "\n",
    "#bwa-mem alignment using 6 threads for all lanes (~average 16 lanes per sample)\n",
    "${BWA} mem -t 6 ${ref} ${tfq2} | ${SAMTOOLS} view -Sb - > ${out2}_mem.bam\n",
    "\n",
    "# sort\n",
    "${SAMTOOLS2} sort -@ 8 -T ${out2}_mem.bam -O bam -o ${out2}_mem.bam ${out2}_mem_srt.bam  \n",
    "\n",
    "#merge\n",
    "${SAMTOOLS2} merge -f -@ 8 ${out2}_mgd_mem_sorted.bam *_mem_*.bam\n",
    "\n",
    "# remove dups\n",
    "${SAMTOOLS2} rmdup -s ${out2}_mgd_mem_sorted.bam ${out2}_mgd_mem_sorted_rmdup.bam\n",
    "\n",
    "#THE FOLLOWING COMMANDS RUN THE MAIN STATS FOR THE ALN SEQUENCES BEFORE AND AFTER REMOVING PCR DUPLICATES\n",
    "${SAMTOOLS2} flagstat ${out2}_mgd_mem_sorted.bam > ${out2}_mgd_mem_sorted_stats.txt \n",
    "${SAMTOOLS2} flagstat ${out2}_mgd_mem_sorted_rmdup.bam > ${out2}_mgd_mem_sorted_rmdup_stats.txt\n",
    "\n",
    "###\n",
    "\n",
    "#---\n",
    "# processing input samples\n",
    "\n",
    "###\n",
    "#bwa-mem alignment\n",
    "\n",
    "#bwa-mem alignment using 6 threads for all lanes (~average 16 lanes per sample)\n",
    "${BWA} mem -t 6 ${ref} ${tfq3} | ${SAMTOOLS2} view -Sb - > ${out3}_mem.bam\n",
    "\n",
    "# sort\n",
    "${SAMTOOLS2} sort -@ 8 -T ${out3}_mem.bam -O bam -o ${out3}_mem_srt.bam  \n",
    "\n",
    "#merge\n",
    "${SAMTOOLS2} merge -f -@ 8 ${out3}_mgd_mem_sorted.bam *_mem_*.bam\n",
    "\n",
    "# remove dups\n",
    "${SAMTOOLS2} rmdup -s ${out3}_mgd_mem_sorted.bam ${out3}_mgd_mem_sorted_rmdup.bam\n",
    "\n",
    "#THE FOLLOWING COMMANDS RUN THE MAIN STATS FOR THE ALN SEQUENCES BEFORE AND AFTER REMOVING PCR DUPLICATES\n",
    "${SAMTOOLS2} flagstat ${out3}_mgd_mem_sorted.bam > ${out3}_mgd_mem_sorted_stats.txt \n",
    "${SAMTOOLS2} flagstat ${out3}_mgd_mem_sorted_rmdup.bam > ${out3}_mgd_mem_sorted_rmdup_stats.txt\n",
    "\n",
    "\n",
    "#----------------------------------------------------------------------\n",
    "# peak calling\n",
    "\n",
    "# 27ac peaks\n",
    "# macs2\n",
    "# q is for q-value, corresponding to FDR\n",
    "# info here: https://github.com/taoliu/MACS/\n",
    "macs2 callpeak -t ${out1}_samse_sorted_rmdup.bam \\\\\n",
    "-c ${out3}_samse_sorted_rmdup.bam -f BAM -g hs -n ${out1}_CSpeaks --no model --m 30 40 --extsize 147 -B -q 0.01\n",
    "\n",
    "# me1 peaks\n",
    "macs2 callpeak -t ${out2}_samse_sorted_rmdup.bam \\\\\n",
    "-c ${out3}_samse_sorted_rmdup.bam -f BAM -g hs -n ${out2}_CSpeaks --no model --m 30 40 --extsize 147 -B -q 0.01\n",
    "\n",
    "\n",
    "#-------------------\n",
    "#clean up\n",
    "\n",
    "mkdir -p ${wkdir}/aln/flagstats/ ${wkdir}/peaks/\n",
    "\n",
    "mv ${out1}_samse*.bam ${out2}_samse*.bam ${out3}_samse*.bam ${wkdir}/aln/\n",
    "\n",
    "mv ${out1}_samse_sorted_*stats.txt ${out2}_samse_sorted_*stats.txt ${wkdir}/aln/flagstats/\n",
    "\n",
    "mv ${out1}_CSpeaks_*.* ${out2}_CSpeaks_*.* ${wkdir}/peaks/\n",
    "\n",
    "\n",
    "\"\"\"%(i, fq1, fq2, fq3, ref, tfq1, tfq2, tfq3, out1, out2, out3, chref)\n",
    "\n",
    "    bsublist.append(bsubbatch)\n",
    "\n",
    "    for x in bsublist:\n",
    "        bsubhandle.write(x)\n",
    "    bsubhandle.close()\n",
    "\n",
    "for line in open('primates/chipseq/samples.txt', 'r').readlines():\n",
    "    \n",
    "    # example samples.txt\n",
    "    # \n",
    "    # Basil FGC1154_s_7_TCTCGCGC-GGCTCTGA.fastq \\\\\n",
    "    # FGC1154_s_7_AGCGATAG-GGCTCTGA.fastq \\\\\n",
    "    # FGC1154_s_7_ATTACTCG-AGGCGAAG.fastq \\\\\n",
    "    # micMur1/micMur1bwaidx \\\\\n",
    "    # FGC1154_s_7_TCTCGCGC-GGCTCTGA_trimmed.fq \\\\\n",
    "    # FGC1154_s_7_AGCGATAG-GGCTCTGA_trimmed.fq \\\\\n",
    "    # FGC1154_s_7_ATTACTCG-AGGCGAAG_trimmed.fq \\\\\n",
    "    # ML_7022f_Basil_H3K27Ac \\\\\n",
    "    # ML_7022f_Basil_H3K4me1 \\\\\n",
    "    # ML_7022f_Basil_INPUT micMur1.chrom.sizes\n",
    "    \n",
    "    line = line.rstrip().split(' ')\n",
    "    \n",
    "    i = line[0]\n",
    "    fq1 = line[1]\n",
    "    fq2 = line[2]\n",
    "    fq3 = line[3]\n",
    "    ref = line[4]\n",
    "    tfq1 = line[5]\n",
    "    tfq2 = line[6]\n",
    "    tfq3 = line[7]\n",
    "    out1 = line[8]\n",
    "    out2 = line[9]\n",
    "    out3 = line[10]\n",
    "    chref = line[11]\n",
    "    \n",
    "    mastercall(i)\n",
    "    bsubcall(i, fq1, fq2, fq3, ref, tfq1, tfq2, tfq3, out1, out2, out3, chref)\n",
    "    \n",
    "    master = scriptdir + \"/\" + str(i) + \".fastqc.macs.bsub\"\n",
    "\n",
    "    bsubline = \"bsub < \" + master\n",
    "    os.system(bsubline)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ChIP-seq QC and strand correlation analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%writefile 'CHIPSEQ.QC.SH'\n",
    "\n",
    "# Marco Trizzino\n",
    "\n",
    "############################### PEAK CALLING QC\n",
    "### FRACTION OF READS IN PEAKS (FRiP)\n",
    "\n",
    "\n",
    "#CALLING THE VARIABLES\n",
    "echo $1 # Chip-seq sample name\n",
    "\n",
    "#Intersect the bam file (aln) with the bed file (peaks locations)\n",
    "bedtools intersect -abam $1_mgd_mem_sorted_rmdup.bam \\\\\n",
    "-b /$1_CSpeaks.narrowPeak -bed -c -f 0.20 > $1_intersect.bed\n",
    "\n",
    "#Count how many reads you have in the peaks, using publicly available perl script: \n",
    "#(https://github.com/mel-astar/mel-ngs/blob/master/mel-chipseq/chipseq-metrics/getCnt.pl)\n",
    "perl getCnt.pl $1_intersect.bed > $1_FRiP.txt\n",
    "\n",
    "\n",
    "### STRAND CORRELATION ANALYSES USING Phantompeakqualtools\n",
    "\n",
    "\n",
    "#CALLING THE VARIABLES\n",
    "echo $1 # bam Chip-seq sample name\n",
    "\n",
    "Rscript --max-ppsize=500000 /phantompeakqualtools/run_spp.R \\\\\n",
    "-c=$1_mgd_mem_sorted_rmdup.bam -savp -odir=/OUTPUT_PATH/ -out=$1_run_spp.out\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "consensus peak calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%writefile 'CONSENSUS.PEAK.CALLING.SH'\n",
    "\n",
    "# Marco\n",
    "\n",
    "############################ USING INDIVIDUAL THAT PASSED INDIVIDUAL PEAK CALLING \n",
    "#PERFORM SPECIES CONSENSUS PEAK CALLING\n",
    "#!/bin/bash\n",
    "\n",
    "#E.G. CONSENSUS H3K27Ac PEAKS\n",
    "#CALLING THE VARIABLES\n",
    "echo $1 # chip bam rep1 \n",
    "echo $2 # chip bam rep2 \n",
    "echo $3 # chip bam rep3 \n",
    "echo $4 # input bam\n",
    "echo $5 # Sample output name\n",
    "\n",
    "#CALLING PEAKS\n",
    "macs2 callpeak -t $1 $2 $3 -c $4 -f BAM -g hs -n $5_CSpeaks --no model --m 30 40 --extsize 147 -B -q 0.01\n",
    "#YOU WILL GET SEVERAL OUTPUTS IN EXEL, BED AND BEDGRAPH FORMATS, \n",
    "# SEE HERE FOR A DESCRIPTION: https://github.com/taoliu/MACS/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "differential binding analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%writefile 'chipseq_analysis.r'\n",
    "\n",
    "################################## \n",
    "#USED 39 EUTHERIAN MAMMALS MULTISPECIES ALIGNMENT FROM ENSEMBL \n",
    "# TO DEFINE REGIONS ORTHOLOGOUS TO HUMAN CONSENSUS PEAKS. \n",
    "#AFTER DETECTING THE ORTHOLOGOUS (SEE YoSon's METHOD), \n",
    "# MAP READ COUNTS FROM EACH SPECIES TO THE HUMAN ORTHOLOGOUS REGIONS FOR H3K27Ac, H3K4me1 and iNPUT\n",
    "### SEE SPECIFIC SCRIPT IN THE SUPPLEMENTARY MATHERIALS\n",
    "### FINAL OUTPUT ARE THREE MATRIXES WITH ORTHOLOGOUS REGIONS AND \n",
    "### H3K27Ac (MATRIX1), H3K4me1 (MATRIX2) and INPUT (MATRIX3) RESPECTIVELY\n",
    "\n",
    "################################## FORM THE THREE MATRIXES, \n",
    "### NORMALIZE CHIP-SEQ READ COUNT BY SEQUENCING DEPTH\n",
    "\n",
    "## EXAMPLE HUMAN B16\n",
    "READ_COUNTS=read.csv(\"MATRIX_REGIONS_ORTHOLOGOUS_TO_HUMAN_CONSENSUS_PEAKS_READ_COUNTS.csv\", \n",
    "                     header = TRUE, row.names = 1)\n",
    "H3K27Ac_total_depth=read.csv(\"27Ac_total.csv\", header = TRUE)\n",
    "# OPEN MATRIX WITH TOTAL NUMBER OF READS PER EACH INDIVIDUAL FOR H3K27Ac (= SEQ DEPTH)\n",
    "\n",
    "READ_COUNTS$HS_B16_H3K27Ac=(READ_COUNTS$HS_B16_H3K27Ac/H3K27Ac_total_depth$B16_H3K27Ac)*1000\n",
    "READ_COUNTS=round(READ_COUNTS,0)\n",
    "\n",
    "\n",
    "\n",
    "###################### FOR BOTH H3K27Ac and H3K4me1 INDEPENDENTLY, \n",
    "#PERFORM DIFFERENTIAL CHIP-SEQ BINDING ANALYSES WITH DEseq2 \n",
    "#ON THE ORTHOLOGOUS COUNT MATRIX NORMALIZED BY SEQUENCING DEPTH\n",
    "\n",
    "#Download DESeq2 from Bioconductor (only need to do the first time you use DESeq2):\n",
    "source(\"http://bioconductor.org/biocLite.R\")\n",
    "biocLite(\"DESeq2\")\n",
    "library(\"DESeq2\")\n",
    "\n",
    "\n",
    "########## H3K27Ac first\n",
    "\n",
    "#Import your expression matrix- mine was a comma seperated values file\n",
    "Nreads <-read.csv(\"H3K27Ac_GENE_COUNTS_ORTHOLOGOUS_NORM_FEAT_LENGTH.csv\", header=TRUE, row.names=1)\n",
    "#CRITICAL: You need to use read counts for DESeq2, not normalized data like RPKMs (see manual).\n",
    "#If read counts are not integers, they need to be round up to integers:\n",
    "Nreads_norm=round(Nreads,0)\n",
    "#Omit any genes with zero counts across samples:\n",
    "Nreads <- Nreads[rowSums(Nreads)!=0,]\n",
    "#genes that have count=0 in only some of the genes need to be an integer > 0\n",
    "Nreads=Nreads+1\n",
    "\n",
    "#Now import a data frame that provides annotatios for the samples \n",
    "#The rows of this correspond to your samples, column 1 has the name of the sample, \n",
    "#column two the condition (=species or species group), column three is the assay (CHIP or INPUT)\n",
    "#for humans vs other primates:\n",
    "colData1 <-read.csv(\"colData_HSvsOTHER.csv\", header=TRUE, row.names=1) #HS VS ALL SPECIES\n",
    "#for apes vs other primates:\n",
    "colData2 <-read.csv(\"colData_APESvsALL.csv\", header=TRUE, row.names=1) #APES VS ALL SPECIES\n",
    "#for all species vs all species pair-wise comparisons:\n",
    "colData3 <-read.csv(\"colData_ALL_SPECIES.csv\", header=TRUE, row.names=1) #ALL SPECIES VS ALL SPECIES\n",
    "\n",
    "\n",
    "#ANALYSIS 1: HS Vs OTHERS (WALD TEST FOR INTERACTION ANALYSIS WITH INPUT) no fold change, FDR=0.10\n",
    "\n",
    "dds <- DESeqDataSetFromMatrix(countData = Nreads, \n",
    "                              colData=colData1, design=~assay + condition + assay:condition)\n",
    "dds = DESeq(dds, test = \"Wald\")\n",
    "\n",
    "res_HS_OTHER<-results(dds, contrast=c(\"condition\",\"HS\",\"OTHER\"))\n",
    "#Remove those genes for which a multiple correction p-value is \"NA\"\n",
    "res_HS_OTHER_p=res_HS_OTHER[!is.na(res_HS_OTHER$padj), ] \n",
    "#Only keep genes with corrected p-values below 0.10:\n",
    "res_HS_OTHER_p=res_HS_OTHER_p[res_HS_OTHER_p$padj<0.10,] \n",
    "#Save logfile\n",
    "write.csv(as.data.frame(res_HS_OTHER_p), file = \"HSVsOTHER_Dbinding_27Ac.csv\")\n",
    "#Get the names of upbound enhancers (HS>other): they are human specific enhancers\n",
    "HighHS_OTHER=rownames(res_HS_OTHER_p[res_HS_OTHER_p$log2FoldChange>0,])\n",
    "write.csv(as.data.frame(HighHS_OTHER), file = \"human_specific_enh_27Ac.csv\")\n",
    "\n",
    "\n",
    "#ANALYSIS 2: APES Vs OTHERS (WALD TEST FOR INTERACTION ANALYSIS WITH INPUT) no fold change, FDR=0.10\n",
    "\n",
    "dds <- DESeqDataSetFromMatrix(countData = Nreads, \n",
    "                              colData=colData2, design=~assay + condition + assay:condition)\n",
    "dds = DESeq(dds, test = \"Wald\")\n",
    "\n",
    "res_APES_OTHER<-results(dds, contrast=c(\"condition\",\"APES\",\"OTHER\"))\n",
    "#Remove those genes for which a multiple correction p-value is \"NA\"\n",
    "res_APES_OTHER_p=res_APES_OTHER[!is.na(res_APES_OTHER$padj), ] \n",
    "#Only keep genes with corrected p-values below 0.10:\n",
    "res_APES_OTHER_p=res_APES_OTHER_p[res_APES_OTHER_p$padj<0.10,] \n",
    "#Save logfile\n",
    "write.csv(as.data.frame(res_APES_OTHER_p), file = \"APESVsOTHER_Dbinding_27Ac.csv\")\n",
    "#Get the names of upbound enhancers (HS>other): they are apes specific enh\n",
    "HighAPES_OTHER=rownames(res_APES_OTHER_p[res_APES_OTHER_p$log2FoldChange>0,])\n",
    "write.csv(as.data.frame(HighAPES_OTHER), file = \"apes_specific_enh_27Ac.csv\")\n",
    "\n",
    "\n",
    "#Now all of the possible human vs any other species pair-wise combinations no fold change, FDR=0.05\n",
    "\n",
    "dds <- DESeqDataSetFromMatrix(countData = Nreads, \n",
    "                              colData=colData3, design=~assay + condition + assay:condition)\n",
    "dds = DESeq(dds, test = \"Wald\")\n",
    "\n",
    "# 'HS' vs 'CH' \n",
    "res_HS_CH<-results(dds, contrast=c(\"condition\",\"HS\",\"CH\"))\n",
    "#Remove those genes for which a multiple correction p-value is \"NA\"\n",
    "res_HS_CH_p=res_HS_CH[!is.na(res_HS_CH$padj), ] \n",
    "#Only keep genes with corrected p-values below 0.10:\n",
    "res_HS_CH_p=res_HS_CH_p[res_HS_CH_p$padj<0.10,] \n",
    "#Save logfile\n",
    "write.csv(as.data.frame(res_HS_CH_p), file = \"HSVsCH_Dbinding_27Ac.csv\")\n",
    "\n",
    "# 'HS' vs 'BB' \n",
    "res_HS_BB<-results(dds, contrast=c(\"condition\",\"HS\",\"BB\"))\n",
    "#Remove those genes for which a multiple correction p-value is \"NA\"\n",
    "res_HS_BB_p=res_HS_BB[!is.na(res_HS_BB$padj), ] \n",
    "#Only keep genes with corrected p-values below 0.10:\n",
    "res_HS_BB_p=res_HS_BB_p[res_HS_BB_p$padj<0.10,] \n",
    "#Save logfile\n",
    "write.csv(as.data.frame(res_HS_BB_p), file = \"HSVsBB_Dbinding_27Ac.csv\")\n",
    "\n",
    "#'HS' vs 'RH' no fold change\n",
    "res_HS_RH<-results(dds, contrast=c(\"condition\",\"HS\",\"RH\"))\n",
    "#Remove those genes for which a multiple correction p-value is \"NA\"\n",
    "res_HS_RH_p=res_HS_RH[!is.na(res_HS_RH$padj), ] \n",
    "#Only keep genes with corrected p-values below 0.10:\n",
    "res_HS_RH_p=res_HS_RH_p[res_HS_RH_p$padj<0.10,] \n",
    "#Save logfile\n",
    "write.csv(as.data.frame(res_HS_RH_p), file = \"HSVsRH_Dbinding_27Ac.csv\")\n",
    "\n",
    "#'HS' vs 'MS' no fold change\n",
    "res_HS_MS<-results(dds, contrast=c(\"condition\",\"HS\",\"MS\"))\n",
    "#Remove those genes for which a multiple correction p-value is \"NA\"\n",
    "res_HS_MS_p=res_HS_MS[!is.na(res_HS_MS$padj), ] \n",
    "#Only keep genes with corrected p-values below 0.10:\n",
    "res_HS_MS_p=res_HS_MS_p[res_HS_MS_p$padj<0.10,] \n",
    "#Save logfile\n",
    "write.csv(as.data.frame(res_HS_MS_p), file = \"HSVsMS_Dbinding_27Ac.csv\")\n",
    "\n",
    "#HS' vs 'ML' no fold change\n",
    "res_HS_ML<-results(dds, contrast=c(\"condition\",\"HS\",\"ML\"))\n",
    "#Remove those genes for which a multiple correction p-value is \"NA\"\n",
    "res_HS_ML_p=res_HS_ML[!is.na(res_HS_ML$padj), ] \n",
    "#Only keep genes with corrected p-values below 0.10:\n",
    "res_HS_ML_p=res_HS_ML_p[res_HS_ML_p$padj<0.10,] \n",
    "#Save logfile\n",
    "write.csv(as.data.frame(res_HS_ML_p), file = \"HSVsML_Dbinding_27Ac.csv\")\n",
    "\n",
    "########## H3K4me1 now\n",
    "\n",
    "#Import your expression matrix- mine was a comma seperated values file\n",
    "Nreads <-read.csv(\"H3K4me1_GENE_COUNTS_ORTHOLOGOUS_NORM_FEAT_LENGTH.csv\", header=TRUE, row.names=1)\n",
    "#CRITICAL: You need to use read counts for DESeq2, not normalized data like RPKMs (see manual).\n",
    "#If read counts are not integers, they need to be round up to integers:\n",
    "Nreads_norm=round(Nreads,0)\n",
    "#Omit any genes with zero counts across samples:\n",
    "Nreads <- Nreads[rowSums(Nreads)!=0,]\n",
    "#genes that have count=0 in only some of the genes need to be an integer > 0\n",
    "Nreads=Nreads+1\n",
    "\n",
    "#Now import a data frame that provides annotatios for the samples \n",
    "#The rows of this correspond to your samples, \n",
    "#column 1 has the name of the sample, \n",
    "#column two the condition (=species or species group), \n",
    "#column three is the assay (CHIP or INPUT)\n",
    "#for humans vs other primates:\n",
    "colData1 <-read.csv(\"colData_HSvsOTHER.csv\", header=TRUE, row.names=1) #HS VS ALL SPECIES\n",
    "#for apes vs other primates:\n",
    "colData2 <-read.csv(\"colData_APESvsALL.csv\", header=TRUE, row.names=1) #APES VS ALL SPECIES\n",
    "#for all species vs all species pair-wise comparisons:\n",
    "colData3 <-read.csv(\"colData_ALL_SPECIES.csv\", header=TRUE, row.names=1) #ALL SPECIES VS ALL SPECIES\n",
    "\n",
    "\n",
    "#ANALYSIS 1: HS Vs OTHERS (WALD TEST FOR INTERACTION ANALYSIS WITH INPUT) no fold change, \n",
    "#FDR=0.10\n",
    "\n",
    "dds <- DESeqDataSetFromMatrix(countData = Nreads, \n",
    "                              colData=colData1, design=~assay + condition + assay:condition)\n",
    "dds = DESeq(dds, test = \"Wald\")\n",
    "\n",
    "res_HS_OTHER<-results(dds, contrast=c(\"condition\",\"HS\",\"OTHER\"))\n",
    "#Remove those genes for which a multiple correction p-value is \"NA\"\n",
    "res_HS_OTHER_p=res_HS_OTHER[!is.na(res_HS_OTHER$padj), ] \n",
    "#Only keep genes with corrected p-values below 0.10:\n",
    "res_HS_OTHER_p=res_HS_OTHER_p[res_HS_OTHER_p$padj<0.10,] \n",
    "#Save logfile\n",
    "write.csv(as.data.frame(res_HS_OTHER_p), file = \"HSVsOTHER_Dbinding_me1.csv\")\n",
    "#Get the names of upbound enhancers (HS>other): they are human specific enhancers\n",
    "HighHS_OTHER=rownames(res_HS_OTHER_p[res_HS_OTHER_p$log2FoldChange>0,])\n",
    "write.csv(as.data.frame(HighHS_OTHER), file = \"human_specific_enh_me1.csv\")\n",
    "\n",
    "\n",
    "#ANALYSIS 2: APES Vs OTHERS (WALD TEST FOR INTERACTION ANALYSIS WITH INPUT) no fold change, FDR=0.10\n",
    "\n",
    "dds <- DESeqDataSetFromMatrix(countData = Nreads, \n",
    "                              colData=colData2, design=~assay + condition + assay:condition)\n",
    "dds = DESeq(dds, test = \"Wald\")\n",
    "\n",
    "res_APES_OTHER<-results(dds, contrast=c(\"condition\",\"APES\",\"OTHER\"))\n",
    "#Remove those genes for which a multiple correction p-value is \"NA\"\n",
    "res_APES_OTHER_p=res_APES_OTHER[!is.na(res_APES_OTHER$padj), ] \n",
    "#Only keep genes with corrected p-values below 0.10:\n",
    "res_APES_OTHER_p=res_APES_OTHER_p[res_APES_OTHER_p$padj<0.10,] \n",
    "#Save logfile\n",
    "write.csv(as.data.frame(res_APES_OTHER_p), file = \"APESVsOTHER_Dbinding_me1.csv\")\n",
    "#Get the names of upbound enhancers (HS>other): they are apes specific enh\n",
    "HighAPES_OTHER=rownames(res_APES_OTHER_p[res_APES_OTHER_p$log2FoldChange>0,])\n",
    "write.csv(as.data.frame(HighAPES_OTHER), file = \"apes_specific_enh_me1.csv\")\n",
    "\n",
    "\n",
    "#Now all of the possible human vs any other species pair-wise combinations no fold change, FDR=0.05\n",
    "\n",
    "dds <- DESeqDataSetFromMatrix(countData = Nreads, \n",
    "                              colData=colData3, design=~assay + condition + assay:condition)\n",
    "dds = DESeq(dds, test = \"Wald\")\n",
    "\n",
    "# 'HS' vs 'CH' \n",
    "res_HS_CH<-results(dds, contrast=c(\"condition\",\"HS\",\"CH\"))\n",
    "#Remove those genes for which a multiple correction p-value is \"NA\"\n",
    "res_HS_CH_p=res_HS_CH[!is.na(res_HS_CH$padj), ] \n",
    "#Only keep genes with corrected p-values below 0.10:\n",
    "res_HS_CH_p=res_HS_CH_p[res_HS_CH_p$padj<0.10,] \n",
    "#Save logfile\n",
    "write.csv(as.data.frame(res_HS_CH_p), file = \"HSVsCH_Dbinding_me1.csv\")\n",
    "\n",
    "# 'HS' vs 'BB' \n",
    "res_HS_BB<-results(dds, contrast=c(\"condition\",\"HS\",\"BB\"))\n",
    "#Remove those genes for which a multiple correction p-value is \"NA\"\n",
    "res_HS_BB_p=res_HS_BB[!is.na(res_HS_BB$padj), ] \n",
    "#Only keep genes with corrected p-values below 0.10:\n",
    "res_HS_BB_p=res_HS_BB_p[res_HS_BB_p$padj<0.10,] \n",
    "#Save logfile\n",
    "write.csv(as.data.frame(res_HS_BB_p), file = \"HSVsBB_Dbinding_me1.csv\")\n",
    "\n",
    "#'HS' vs 'RH' no fold change\n",
    "res_HS_RH<-results(dds, contrast=c(\"condition\",\"HS\",\"RH\"))\n",
    "#Remove those genes for which a multiple correction p-value is \"NA\"\n",
    "res_HS_RH_p=res_HS_RH[!is.na(res_HS_RH$padj), ] \n",
    "#Only keep genes with corrected p-values below 0.10:\n",
    "res_HS_RH_p=res_HS_RH_p[res_HS_RH_p$padj<0.10,] \n",
    "#Save logfile\n",
    "write.csv(as.data.frame(res_HS_RH_p), file = \"HSVsRH_Dbinding_me1.csv\")\n",
    "\n",
    "#'HS' vs 'MS' no fold change\n",
    "res_HS_MS<-results(dds, contrast=c(\"condition\",\"HS\",\"MS\"))\n",
    "#Remove those genes for which a multiple correction p-value is \"NA\"\n",
    "res_HS_MS_p=res_HS_MS[!is.na(res_HS_MS$padj), ] \n",
    "#Only keep genes with corrected p-values below 0.10:\n",
    "res_HS_MS_p=res_HS_MS_p[res_HS_MS_p$padj<0.10,] \n",
    "#Save logfile\n",
    "write.csv(as.data.frame(res_HS_MS_p), file = \"HSVsMS_Dbinding_me1.csv\")\n",
    "\n",
    "#HS' vs 'ML' no fold change\n",
    "res_HS_ML<-results(dds, contrast=c(\"condition\",\"HS\",\"ML\"))\n",
    "#Remove those genes for which a multiple correction p-value is \"NA\"\n",
    "res_HS_ML_p=res_HS_ML[!is.na(res_HS_ML$padj), ] \n",
    "#Only keep genes with corrected p-values below 0.10:\n",
    "res_HS_ML_p=res_HS_ML_p[res_HS_ML_p$padj<0.10,] \n",
    "#Save logfile\n",
    "write.csv(as.data.frame(res_HS_ML_p), file = \"HSVsML_Dbinding_me1.csv\")\n",
    "\n",
    "\n",
    "###################################################\n",
    "DIFFERENTIAL BINDING ANALYSIS RESULTS ARE IN TABLES4\n",
    "\n",
    "#####################################################################################\n",
    "\n",
    "#### PARSE DIFFERENTIAL CHIP-SEQ BINDING csv OUTPUTS\n",
    "### FOR H3K27Ac and H3K4me1 respectively get:\n",
    "#- List of human specific elements\n",
    "#- List of apes specific elements\n",
    "#- List of conserved elements \n",
    "#(= all of the elements that did not results as differentially expressed in any of the comparisons)\n",
    "#- List of other recently evolved elements \n",
    "#(human specific + ape specific + other elements not conserved)\n",
    "\n",
    "#####################################################################################\n",
    "\n",
    "# In R\n",
    "# using human consensus H3K27Ac and H3K4me1 peak files \n",
    "# (narrowPeak bed file converted to txt format), \n",
    "# using the name of the element (=name of the peak) as an index, \n",
    "# associate peak coordinates to each element in the four file produced in the previous step \n",
    "# (conserved, human specific, apes specific, other recently evolved) \n",
    "\n",
    "#H3K27Ac\n",
    "K27_peaks=read.table(\"CONSENSUS_H3K27Ac_narrowPeakfile.txt\", header = F)\n",
    "human_specific=read.csv(\"human_specific_H3K27Ac_CREs.csv\", header = F)\n",
    "ape_specific=read.csv(\"ape_specific_H3K27Ac_CREs.csv\", header = F)\n",
    "other_recently_evolved=read.csv(\"other_recently_evolved_H3K27Ac_CREs.csv\", header = F)\n",
    "conserved=read.csv(\"other_conserved_H3K27Ac_.csv\", header = F)\n",
    "\n",
    "index<-match(K27_peaks$V4, human_specific$V1)\n",
    "human_specific$chr=K27_peaks$V1[index]\n",
    "human_specific$start=K27_peaks$V2[index]\n",
    "human_specific$end=K27_peaks$end[index]\n",
    "write.csv(as.data.frame(human_specific), \n",
    "          file = 'human_specific_H3K27Ac_CREs_WITH_COORD.csv', row.names = FALSE)\n",
    "\n",
    "index<-match(K27_peaks$V4, ape_specific$V1)\n",
    "ape_specific$chr=K27_peaks$V1[index]\n",
    "ape_specific$start=K27_peaks$V2[index]\n",
    "ape_specific$end=K27_peaks$end[index]\n",
    "write.csv(as.data.frame(ape_specific), \n",
    "          file = 'ape_specific_H3K27Ac_CREs_WITH_COORD.csv', row.names = FALSE)\n",
    "\n",
    "index<-match(K27_peaks$V4, other_recently_evolved$V1)\n",
    "other_recently_evolved$chr=K27_peaks$V1[index]\n",
    "other_recently_evolved$start=K27_peaks$V2[index]\n",
    "other_recently_evolved$end=K27_peaks$end[index]\n",
    "write.csv(as.data.frame(other_recently_evolved), \n",
    "          file = 'other_recently_evolved_H3K27Ac_CREs_WITH_COORD.csv', row.names = FALSE)\n",
    "\n",
    "index<-match(K27_peaks$V4, conserved$V1)\n",
    "conserved$chr=K27_peaks$V1[index]\n",
    "conserved$start=K27_peaks$V2[index]\n",
    "conserved$end=K27_peaks$end[index]\n",
    "write.csv(as.data.frame(conserved), \n",
    "          file = 'conserved_H3K27Ac_CREs_WITH_COORD.csv', row.names = FALSE)\n",
    "\n",
    "#H3K4me1\n",
    "me1_peaks=read.table(\"CONSENSUS_H3K4me1_narrowPeakfile.txt\", header = F)\n",
    "human_specific=read.csv(\"human_specific_H3K4me1_CREs.csv\", header = F)\n",
    "ape_specific=read.csv(\"ape_specific_H3K4me1_CREs.csv\", header = F)\n",
    "other_recently_evolved=read.csv(\"other_recently_evolved_H3K4me1_CREs.csv\", header = F)\n",
    "conserved=read.csv(\"other_conserved_H3K4me1_.csv\", header = F)\n",
    "\n",
    "index<-match(me1_peaks$V4, human_specific$V1)\n",
    "human_specific$chr=me1_peaks$V1[index]\n",
    "human_specific$start=me1_peaks$V2[index]\n",
    "human_specific$end=me1_peaks$end[index]\n",
    "write.csv(as.data.frame(human_specific), \n",
    "          file = 'human_specific_H3K4me1_CREs_WITH_COORD.csv', row.names = FALSE)\n",
    "\n",
    "index<-match(me1_peaks$V4, ape_specific$V1)\n",
    "ape_specific$chr=me1_peaks$V1[index]\n",
    "ape_specific$start=me1_peaks$V2[index]\n",
    "ape_specific$end=me1_peaks$end[index]\n",
    "write.csv(as.data.frame(ape_specific), \n",
    "          file = 'ape_specific_H3K4me1_CREs_WITH_COORD.csv', row.names = FALSE)\n",
    "\n",
    "index<-match(me1_peaks$V4, other_recently_evolved$V1)\n",
    "other_recently_evolved$chr=me1_peaks$V1[index]\n",
    "other_recently_evolved$start=me1_peaks$V2[index]\n",
    "other_recently_evolved$end=me1_peaks$end[index]\n",
    "write.csv(as.data.frame(other_recently_evolved), \n",
    "          file = 'other_recently_evolved_H3K4me1_CREs_WITH_COORD.csv', row.names = FALSE)\n",
    "\n",
    "index<-match(me1_peaks$V4, conserved$V1)\n",
    "conserved$chr=me1_peaks$V1[index]\n",
    "conserved$start=me1_peaks$V2[index]\n",
    "conserved$end=me1_peaks$end[index]\n",
    "write.csv(as.data.frame(conserved), \n",
    "          file = 'conserved_H3K4me1_CREs_WITH_COORD.csv', row.names = FALSE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "functional analysis and annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%writefile 'functional_annotations.sh'\n",
    "\n",
    "\n",
    "##########################\n",
    "# For H3K27Ac and H3K4me1 independently, concatenate the four csv files with coordinates and peak names (human specific, ape specific, other recently evolved, conserved) in  single file\n",
    "\n",
    "cat human_specific_H3K27Ac_CREs_WITH_COORD.csv ape_specific_H3K27Ac_CREs_WITH_COORD.csv other_recently_evolved_H3K27Ac_CREs_WITH_COORD.csv conserved_H3K27Ac_CREs_WITH_COORD.csv > H3K27Ac_CREs_WITH_COORD.csv\n",
    "\n",
    "cat human_specific_H3K4me1_CREs_WITH_COORD.csv ape_specific_H3K4me1_CREs_WITH_COORD.csv other_recently_evolved_H3K4me1_CREs_WITH_COORD.csv conserved_H3K4me1_CREs_WITH_COORD.csv > H3K4me1_CREs_WITH_COORD.csv\n",
    "\n",
    "# With a text editor convert the two concatenated files into two bed files\n",
    "\n",
    "\n",
    "###############################################################\n",
    "## Now, for each of the two histone modifications we have a bed file including: peak name, coordinates (chr, start, end) and conservation status (human specific, ape specific, other recently evolved, conserved)\n",
    "## We use bedtools to check if some of the H3K27Ac peaks overlap some of the H3K4me1 peaks (and vice-versa) for at list the 25% of their length\n",
    "\n",
    "\n",
    "bedtools intersect -a H3K4me1_ANNOTATED_PEAKS.bed -b H3K27Ac_ANNOTATED_PEAKS.bed -f 0.25 -wa -wb > H3K4me1_peaks_overlapping_H3K27Ac_peaks.txt\n",
    "\n",
    "bedtools intersect -a H3K27Ac_ANNOTATED_PEAKS.bed -b H3K4me1_ANNOTATED_PEAKS.bed -f 0.25 -wa -wb > H3K27Ac_peaks_overlapping_H3K4me1_peaks.txt\n",
    "\n",
    "## Concatenate H3K27Ac_ANNOTATED_PEAKS.bed and H3K4me1_ANNOTATED_PEAKS.bed and using the information about the overlapping peaks, include duplicated peaks only once \n",
    "\n",
    "\n",
    "###############################################################\n",
    "## Annotate the matrix of unique not duplicated regulatory elements (i.e. UNIQUE PEAKS) associating closest gene, closest gene typology and distance from TSS of the closest gene\n",
    "\n",
    "# First you need to convert the GTF file of the annotation to a bed format using gtf2bed (from the Bedops suite)\n",
    "\n",
    "gtf2bed GRCh38_ANNOTATIONS.gtf > GRCh38_ANNOTATIONS.bed\n",
    "\n",
    "# Next from the gene annotations bed file (GRCh38_ANNOTATIONS.bed) you need to extract the TSS coordinates (i.e. first base for + strand, last base for  - strand).\n",
    "# Final output will be bed file with TSS coordinates, strand and  gene typology: 'GRCh38_TSSs.bed'\n",
    "\n",
    "# Now associate a TSS to each cis-regulatory element:\n",
    "\n",
    "bedtools closest -a UNIQUE_PEAKS_WITH_COORDINATES.bed -b GRCh38_TSSs.bed > unique_peaks_with_coordinates_annotated.bed\n",
    "\n",
    "## Now for each unique peak we have the following annotations: ID, chr, start, end, additional histone mark (if duplicated peak), coordinates of additional histone mark (if duplicated peak), closest gene ID, closest gene typology, strand, distance from TSS\n",
    "\n",
    "\n",
    "\n",
    "###############################################################\n",
    "#Use publicly available DHS data from ENCODE on 200+ cell types to annotate the unique regulatory element matrix\n",
    "\n",
    "bedtools intersect -a unique_peaks_with_coordinates_annotated.bed -b ENCODE_DHS_DATA.bed -wa -wb > unique_peaks_with_coordinates_annotated_including_cell_types.bed\n",
    "\n",
    "###############################################################\n",
    "#Use publicly available data from ENCODE on TFBS on HepG2 cells to annotate the unique regulatory element matrix\n",
    "\n",
    "bedtools intersect -a unique_peaks_with_coordinates_annotated_including_cell_types.bed -b ENCODE_TFBS_DATA.bed -wa -wb > unique_peaks_with_coordinates_annotated_including_cell_types_and_TFBS.txt\n",
    "\n",
    "\n",
    "## The matrix 'unique_peaks_with_coordinates_annotated_including_cell_types_and_TFBS.txt' includes the following annotations: ID, chr, start, end, additional histone mark (if duplicated peak), coordinates of additional histone mark (if duplicated peak), closest gene ID, closest gene typology, strand, distance from TSS, number of DHS cell types (if any), number of TFBSs in HepG2 (if any)\n",
    "\n",
    "\n",
    "\n",
    "##############################################################\n",
    "## In R environment, using the peak ID as a index, annotate the matrix with normalized read counts for each peak for each species\n",
    "\n",
    "## Example with MARMOSET MS_32842 H3K27Ac counts\n",
    "\n",
    "matrix=read.table('unique_peaks_with_coordinates_annotated_including_cell_types_and_TFBS.txt', header = T)\n",
    "counts=read.csv('H3K27Ac_normalized_counts.csv', header=T)\n",
    "\n",
    "index<-match(matrix$peak_ID, counts$peak_ID)\n",
    "matrix$MS_32842_H3K27Ac=counts$MS_32842_H3K27Ac[index]\n",
    "## Repeat this step for each individual and for each histone mark and input\n",
    "\n",
    "#### The final matrix is TABLES2 and includes the following annotations: ID, chr, start, end, additional histone mark (if duplicated peak), coordinates of additional histone mark (if duplicated peak), closest gene ID, closest gene typology, strand, distance from TSS, number of DHS cell types (if any), number of TFBSs in HepG2 (if any), normalized read counts for each species for each histone mark and input.\n",
    "\n",
    "######################################\n",
    "######################################\n",
    "#TABLE_S2 is used for all the next downstream analyses\n",
    "######################################\n",
    "######################################\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "#MT\n",
    "\n",
    "####################### Script for FIGURE 3\n",
    "\n",
    "## Differentially bound CREs plot (FIGURE 3a)\n",
    "\n",
    "# For each human centric pair-wise comparison quantify fraction of differentially bound CREs \n",
    "# You need to use outputs of DESeq2 analyses\n",
    "\n",
    "cat 'HSVsCH_Dbinding.txt' | wc -l > HS_CH_differentially_bound_numbers.txt\n",
    "cat 'HSVsRH_Dbinding.txt' | wc -l > HS_RH_differentially_bound_numbers.txt\n",
    "cat 'HSVsMS_Dbinding.txt' | wc -l > HS_MS_differentially_bound_numbers.txt\n",
    "cat 'HSVsBB_Dbinding.txt' | wc -l > HS_BB_differentially_bound_numbers.txt\n",
    "cat 'HSVsML_Dbinding.txt' | wc -l > HS_ML_differentially_bound_numbers.txt\n",
    "\n",
    "# Concatenate the text files with the differential binding numbers\n",
    "cat HS_CH_differentially_bound_numbers.txt HS_RH_differentially_bound_numbers.txt HS_MS_differentially_bound_numbers.txt HS_BB_differentially_bound_numbers.txt HS_ML_differentially_bound_numbers.txt > primate_differential_binding_number.txt\n",
    "\n",
    "\n",
    "\n",
    "## Differentially expressed genes plot (Figure 3b)\n",
    "\n",
    "# For each human centric pair-wise comparison quantify fraction of differentially bound CREs \n",
    "# You need to use outputs of DESeq2 analyses\n",
    "\n",
    "cat 'HSVsCH_DE.txt' | wc -l > HS_CH_differentially_expressed_numbers.txt\n",
    "cat 'HSVsRH_DE.txt' | wc -l > HS_RH_differentially_expressed_numbers.txt\n",
    "cat 'HSVsMS_DE.txt' | wc -l > HS_MS_differentially_expressed_numbers.txt\n",
    "cat 'HSVsBB_DE.txt' | wc -l > HS_BB_differentially_expressed_numbers.txt\n",
    "cat 'HSVsML_DE.txt' | wc -l > HS_ML_differentially_expressed_numbers.txt\n",
    "\n",
    "# Concatenate the text files with the differential binding numbers\n",
    "cat HS_CH_differentially_expressed_numbers.txt HS_RH_differentially_expressed_numbers.txt HS_MS_differentially_expressed_numbers.txt HS_BB_differentially_expressed_numbers.txt HS_ML_differentially_expressed_numbers.txt > primate_differential_binding_number.txt\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once all files are formatted, check out differential bindings (bar plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "\n",
    "\n",
    "# In R, Convert number to fractions\n",
    "cres=read.table('primate_differential_binding_number.txt', header = F)\n",
    "cres$V2=(cres$V1/47643)*100\n",
    "\n",
    "# Now you need a column with species names\n",
    "names = matrix(c(chimp, rhesus macaque, marmoset, bushbaby, mouse lemur), nrow=5, ncol=1)\n",
    "\n",
    "# Combine matrix with names with matrix with matrix with fractions\n",
    "differential_binding_matrix=cbind(names$V1, cres$V2)\n",
    "differential_binding_matrix$V1 <- factor(differential_binding_matrix$V1, levels=unique(differential_binding_matrix$V1))\n",
    "\n",
    "#BAR PLOT DIFFERENTIAL BINDING OVER SPECIES\n",
    "ggplot(data=differential_binding_matrix, aes(x=V1, y=V2, fill=V1)) + \n",
    "  geom_bar(stat=\"identity\") + \n",
    "  scale_fill_manual(values = c(\n",
    "      \"CHIMP\"=\"#ff8c00\",\n",
    "      \"RHESUS MACAQUE\"=\"#db7093\",\n",
    "      \"MARMOSET\"=\"#4169e1\",\n",
    "      \"BUSHBABY\"=\"#00ced1\",\n",
    "      \"MOUSE LEMUR\"=\"#0000cd\")) +\n",
    "  labs(x=\"\\nSPECIES\",y=\"DIFFERENTIALLY BOUND CREs FRACTION (%)\\n\") +\n",
    "  theme_minimal() +\n",
    "  theme(axis.title=element_text(size=20), axis.text=element_text(size=20))\n",
    "  \n",
    "\n",
    "\n",
    "# In R, convert number to fractions\n",
    "DE=read.table('primate_differential_expressed_number.txt', header = F)\n",
    "DE$V2=(DE$V1/47643)*100\n",
    "\n",
    "# Now you need a column with species names\n",
    "names = matrix(c(chimp, rhesus macaque, marmoset, bushbaby, mouse lemur), nrow=5, ncol=1)\n",
    "\n",
    "# Combine matrix with names with matrix with matrix with fractions\n",
    "differential_expression_matrix=cbind(names$V1, cres$V2)\n",
    "differential_expression_matrix$V1 <- factor(differential_expression_matrix$V1, levels=unique(differential_expression_matrix$V1))\n",
    "\n",
    "#BAR PLOT DIFFERENTIAL EXPRESSION OVER SPECIES\n",
    "ggplot(data=differential_expression_matrix, aes(x=V1, y=V2, fill=V1)) + \n",
    "  geom_bar(stat=\"identity\") +\n",
    "  scale_fill_manual(values = c(\n",
    "      \"CHIMP\"=\"#ff8c00\",\n",
    "      \"RHESUS MACAQUE\"=\"#db7093\",\n",
    "      \"MARMOSET\"=\"#4169e1\",\n",
    "      \"BUSHBABY\"=\"#00ced1\",\n",
    "      \"MOUSE LEMUR\"=\"#0000cd\")) +\n",
    "  labs(x=\"\\nSPECIES\",y=\"DIFFERENTIALLY EXPRESSED GENES FRACTION (%)\\n\") +\n",
    "  theme_minimal() +\n",
    "  theme(axis.title=element_text(size=20), axis.text=element_text(size=20))\n",
    "  \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "\n",
    "####################### Script for FIGURE 4\n",
    "\n",
    "######### Gene typologies: Figure 4a\n",
    "\n",
    "## From TABLES2.txt, extract conserved and recently evolved CREs\n",
    "cat TABLE2.txt | grep \"conserved\"  > conserved_CREs.txt\n",
    "cat TABLE2.txt | grep -e \"human_specific\" -e \"apes_specific\" -e \"other_recently_evolved\"  > recently_evolved_CREs.txt\n",
    "\n",
    "# Count conserved and recently evolved CREs associated to protein coding genes\n",
    "cat conserved_CREs.txt | grep \"protein\" | wc -l > conserved_protein_coding_numbers.txt\n",
    "cat recently evolved_CREs.txt | grep \"protein\" | wc -l > recently_evolved_protein_coding_numbers.txt\n",
    "\n",
    "# Count conserved and recently evolved CREs associated to lincRNAs\n",
    "cat conserved_CREs.txt | grep \"lincRNA\" | wc -l > conserved_lincRNA_numbers.txt\n",
    "cat recently evolved_CREs.txt | grep \"lincRNA\" | wc -l > recently_evolved_lincRNA_numbers.txt\n",
    "\n",
    "# Count conserved and recently evolved CREs associated to pseudogenes\n",
    "cat conserved_CREs.txt | grep \"pseudogene\" | wc -l > conserved_pseudogene_numbers.txt\n",
    "cat recently evolved_CREs.txt | grep \"pseudogene\" | wc -l > recently_pseudogene_lincRNA_numbers.txt\n",
    "\n",
    "# Concatenate all of the conserved, adding also the total number of conserved and the total number of labile derived from Figure 2 analyses (conserved_number.txt and recently_evolved_number.txt files)\n",
    "cat conserved_number.txt recently_evolved_numbers. txt conserved_protein_coding_numbers.txt recently_evolved_protein_coding_numbers.txt conserved_lincRNA_numbers.txt recently_evolved_lincRNA_numbers.txt conserved_pseudogene_numbers.txt recently_evolved_pseudogene_numbers.txt > gene_types_N.txt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "\n",
    "#MT\n",
    "\n",
    "## In R environment\n",
    "gene_types = read.table('gene_types_N.txt', header = F)\n",
    "\n",
    "# Convert numbers to fractions\n",
    "gene_types$V2=(gene_types $V1/47643)*100\n",
    "\n",
    "# Build a matrix with gene type names\n",
    "gene_type_names = matrix(c(all_conserved, all_recently_evolved, protein_coding_conserved, protein_coding_recently_evolved, lincRNA_conserved, lincRNA_recently_evolved, pseudogene_conserved_pseudogene_reently_evolved), nrow=8, ncol=1)\n",
    "\n",
    "# Bind the three matrixes\n",
    "matrix = cbind(gene_type_names$V1, gene_types$V2)\n",
    "\n",
    "# PLOT them\n",
    "ggplot(data=matrix, aes(x=V1, y=V2, fill=V1)) + geom_bar(stat=\"identity\") +  scale_fill_manual(values = c(\n",
    "  \"all_conserved\"=\"#0073ff\",\n",
    "  \"all_recently_evolved\"=\"#ff0d00\",   \n",
    "  \"protein_coding_conserved\"=\"#0073ff\",\n",
    "  \"protein_coding_recently_evolved\"=\"#ff0d00\",\n",
    "  \"lincRNA_conserved\"=\"#0073ff\",\n",
    "  \"lincRNA_recently_evolved\" =\"#ff0d00\",\n",
    "  \"Pseudogenes_conserved\"=\"#0073ff\",\n",
    "  \"Pseudogenes_recently_evolved\" =\"#ff0d00\"))+\n",
    "  labs(x=\"\\nGENE CATEGORY\",y=\"FRACTION OF THE GENES ASSOCIATED CREs (%)\\n\")+\n",
    "  scale_x_discrete(limits=c(\"all_conserved\", \"all_recently_evolved\", \"\",\"protein_coding_conserved\",\"protein_coding_recently_evolved\",\"\",\"lincRNA_conserved\",\"lincRNA_recently_evolved\",\"\",\"Pseudogenes_conserved\", \"Pseudogenes_recently_evolved\"))+\n",
    "  theme_minimal()+\n",
    "  theme(axis.title=element_text(size=16), axis.text=element_text(size=16))+\n",
    "  theme(axis.text.x = element_text(angle = 90, hjust = 1))\n",
    "  \n",
    "  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "#MT\n",
    "\n",
    "######## TSS distances: Figure 4b\n",
    "\n",
    "# Break down the conserved and labile CREs by species, including the annotations on the distance from the closest TSS from Table S2 \n",
    "\n",
    "#Example: CHIMP\n",
    "\n",
    "# Concatenate the differential binding analyses outputs from the human Vs chimp comparison in H3K27Ac and H3K4me1\n",
    "cat HSVsCH_Dbinding_27Ac.csv HSVsCH_Dbinding_me1.csv > HSVsCH_Dbinding_all.csv\n",
    "cat HSVsRH_Dbinding_27Ac.csv HSVsRH_Dbinding_me1.csv > HSVsRH_Dbinding_all.csv\n",
    "cat HSVsMS_Dbinding_27Ac.csv HSVsMS_Dbinding_me1.csv > HSVsMS_Dbinding_all.csv\n",
    "cat HSVsBB_Dbinding_27Ac.csv HSVsBB_Dbinding_me1.csv > HSVsBB_Dbinding_all.csv\n",
    "cat HSVsML_Dbinding_27Ac.csv HSVsML_Dbinding_me1.csv > HSVsML_Dbinding_all.csv\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "\n",
    "#MT\n",
    "\n",
    "\n",
    "# In R\n",
    "\n",
    "# For each species:\n",
    "\n",
    "# Chimp\n",
    "chimp_diff=read.csv('HSVsCH_Dbinding_all.csv', header=F)\n",
    "All_CREs=read.table(TABLES2.txt, header=T)\n",
    "index<-match(All_CREs$CRE_ID,chimp_diff$V1)\n",
    "All_CREs$chimp=chimp_diff$V1[index]\n",
    "labile_chimp=na.omit(all_CREs)\n",
    "conserved_chimp=all_CREs[is.na(all_CREs$chimp),]\n",
    "write.csv(as.data.frame(labile_chimp), file = \"Labile_chimp_distances.csv\", row.names = FALSE)\n",
    "write.csv(as.data.frame(conserved_chimp), file = \"Conserved_chimp_distances.csv\", row.names = FALSE)\n",
    "\n",
    "# Rhesus macaque\n",
    "rhesus_diff=read.csv('HSVsRH_Dbinding_all.csv', header=F)\n",
    "All_CREs=read.table(TABLES2.txt, header=T)\n",
    "index<-match(All_CREs$CRE_ID,rhesus_diff$V1)\n",
    "All_CREs$rhesus=rhesus_diff$V1[index]\n",
    "labile_rhesus=na.omit(all_CREs)\n",
    "conserved_rhesus=all_CREs[is.na(all_CREs$rhesus),]\n",
    "write.csv(as.data.frame(labile_rhesus), file = \"Labile_rhesus_distances.csv\", row.names = FALSE)\n",
    "write.csv(as.data.frame(conserved_rhesus), file = \"Conserved_rhesus_distances.csv\", row.names = FALSE)\n",
    "\n",
    "# Marmoset\n",
    "marmoset_diff=read.csv('HSVsMS_Dbinding_all.csv', header=F)\n",
    "All_CREs=read.table(TABLES2.txt, header=T)\n",
    "index<-match(All_CREs$CRE_ID,marmoset_diff$V1)\n",
    "All_CREs$marmoset=marmoset_diff$V1[index]\n",
    "labile_marmoset=na.omit(all_CREs)\n",
    "conserved_marmoset=all_CREs[is.na(all_CREs$marmoset),]\n",
    "write.csv(as.data.frame(labile_marmoset), file = \"Labile_marmoset_distances.csv\", row.names = FALSE)\n",
    "write.csv(as.data.frame(conserved_marmoset), file = \"Conserved_marmoset_distances.csv\", row.names = FALSE)\n",
    "\n",
    "# Bushbaby\n",
    "bushbaby_diff=read.csv('HSVsBB_Dbinding_all.csv', header=F)\n",
    "All_CREs=read.table(TABLES2.txt, header=T)\n",
    "index<-match(All_CREs$CRE_ID,bushbaby_diff$V1)\n",
    "All_CREs$bushbaby=bushbaby_diff$V1[index]\n",
    "labile_bushbaby=na.omit(all_CREs)\n",
    "conserved_bushbaby=all_CREs[is.na(all_CREs$bushbaby),]\n",
    "write.csv(as.data.frame(labile_bushbaby), file = \"Labile_bushbaby_distances.csv\", row.names = FALSE)\n",
    "write.csv(as.data.frame(conserved_bushbaby), file = \"Conserved_bushbaby_distances.csv\", row.names = FALSE)\n",
    "\n",
    "# Mouse lemur\n",
    "mouse_lemur_diff=read.csv('HSVsML_Dbinding_all.csv', header=F)\n",
    "All_CREs=read.table(TABLES2.txt, header=T)\n",
    "index<-match(All_CREs$CRE_ID,mouse_lemur_diff$V1)\n",
    "All_CREs$mouse_lemur=mouse_lemur_diff$V1[index]\n",
    "labile_mouse_lemur=na.omit(all_CREs)\n",
    "conserved_mouse_lemur=all_CREs[is.na(all_CREs$mouse_lemur),]\n",
    "write.csv(as.data.frame(labile_mouse_lemur), file = \"Labile_mouse_lemur_distances.csv\", row.names = FALSE)\n",
    "write.csv(as.data.frame(conserved_mouse_lemur), file = \"Conserved_mouse_lemur_distances.csv\", row.names = FALSE)\n",
    "\n",
    "\n",
    "## In each of the produced species dataframe, compute the fraction of conserved CREs within each of the following 5 kb windows: 0 kb, 0.1-5, 5-10, 10-15, 15-20, 20-25, 25-30, > 30\n",
    "\n",
    "\n",
    "# chimp\n",
    "conserved=read.csv('Conserved_chimp_distances.csv', header = F)\n",
    "labile=read.csv('Labile_chimp_distances.csv', header = F)\n",
    "\n",
    "chimp_conserved0kb = (sum( conserved$V1 == 0 )/(sum( conserved$V1 == 0 ) + sum( labile$V1 == 0  ))) *100\n",
    "chimp_conserved0_5kb = (sum( 0 %<% conserved$V1 %<% 5 )/(sum( 0 %<% conserved$V1 %<% 5 ) + sum( 0 %<% labile$V1 %<% 5 ))) *100\n",
    "chimp_conserved5_10kb = (sum( 5 %<% conserved$V1 %<% 10 )/(sum( 5 %<% conserved$V1 %<% 10 ) + sum( 5 %<% labile$V1 %<% 10 ))) *100\n",
    "chimp_conserved10_15kb = (sum( 10 %<% conserved$V1 %<% 15 )/(sum( 10 %<% conserved$V1 %<% 15 ) + sum( 10 %<% labile$V1 %<% 15 ))) *100\n",
    "chimp_conserved15_20kb = (sum( 15 %<% conserved$V1 %<% 20 )/(sum( 15 %<% conserved$V1 %<% 20 ) + sum( 15 %<% labile$V1 %<% 20 ))) *100\n",
    "chimp_conserved20_25kb = (sum( 20 %<% conserved$V1 %<% 25 )/(sum( 20 %<% conserved$V1 %<% 25 ) + sum( 20 %<% labile$V1 %<% 25 ))) *100\n",
    "chimp_conserved25_30kb = (sum( 25 %<% conserved$V1 %<% 30 )/(sum( 25 %<% conserved$V1 %<% 30 ) + sum( 25 %<% labile$V1 %<% 30 ))) *100\n",
    "chimp_conserved>_30kb = (conserved$V1 %>% 30 )/(sum( conserved$V1 %>% 30  ) + sum( labile$V1 %>% 30  ))) *100\n",
    "\n",
    "\n",
    "# rhesus\n",
    "conserved=read.csv('Conserved_rhesus_distances.csv', header = F)\n",
    "labile=read.csv('Labile_rhesus_distances.csv', header = F)\n",
    "\n",
    "rhesus_conserved0kb = (sum( conserved$V1 == 0 )/(sum( conserved$V1 == 0 ) + sum( labile$V1 == 0  ))) *100\n",
    "rhesus_conserved0_5kb = (sum( 0 %<% conserved$V1 %<% 5 )/(sum( 0 %<% conserved$V1 %<% 5 ) + sum( 0 %<% labile$V1 %<% 5 ))) *100\n",
    "rhesus_conserved5_10kb = (sum( 5 %<% conserved$V1 %<% 10 )/(sum( 5 %<% conserved$V1 %<% 10 ) + sum( 5 %<% labile$V1 %<% 10 ))) *100\n",
    "rhesus_conserved10_15kb = (sum( 10 %<% conserved$V1 %<% 15 )/(sum( 10 %<% conserved$V1 %<% 15 ) + sum( 10 %<% labile$V1 %<% 15 ))) *100\n",
    "rhesus_conserved15_20kb = (sum( 15 %<% conserved$V1 %<% 20 )/(sum( 15 %<% conserved$V1 %<% 20 ) + sum( 15 %<% labile$V1 %<% 20 ))) *100\n",
    "rhesus_conserved20_25kb = (sum( 20 %<% conserved$V1 %<% 25 )/(sum( 20 %<% conserved$V1 %<% 25 ) + sum( 20 %<% labile$V1 %<% 25 ))) *100\n",
    "rhesus_conserved25_30kb = (sum( 25 %<% conserved$V1 %<% 30 )/(sum( 25 %<% conserved$V1 %<% 30 ) + sum( 25 %<% labile$V1 %<% 30 ))) *100\n",
    "rhesus_conserved>_30kb = (conserved$V1 %>% 30 )/(sum( conserved$V1 %>% 30  ) + sum( labile$V1 %>% 30  ))) *100\n",
    "\n",
    "\n",
    "# marmoset\n",
    "conserved=read.csv('Conserved_marmoset_distances.csv', header = F)\n",
    "labile=read.csv('Labile_marmoset_distances.csv', header = F)\n",
    "\n",
    "marmoset_conserved0kb = (sum( conserved$V1 == 0 )/(sum( conserved$V1 == 0 ) + sum( labile$V1 == 0  ))) *100\n",
    "marmoset_conserved0_5kb = (sum( 0 %<% conserved$V1 %<% 5 )/(sum( 0 %<% conserved$V1 %<% 5 ) + sum( 0 %<% labile$V1 %<% 5 ))) *100\n",
    "marmoset_conserved5_10kb = (sum( 5 %<% conserved$V1 %<% 10 )/(sum( 5 %<% conserved$V1 %<% 10 ) + sum( 5 %<% labile$V1 %<% 10 ))) *100\n",
    "marmoset_conserved10_15kb = (sum( 10 %<% conserved$V1 %<% 15 )/(sum( 10 %<% conserved$V1 %<% 15 ) + sum( 10 %<% labile$V1 %<% 15 ))) *100\n",
    "marmoset_conserved15_20kb = (sum( 15 %<% conserved$V1 %<% 20 )/(sum( 15 %<% conserved$V1 %<% 20 ) + sum( 15 %<% labile$V1 %<% 20 ))) *100\n",
    "marmoset_conserved20_25kb = (sum( 20 %<% conserved$V1 %<% 25 )/(sum( 20 %<% conserved$V1 %<% 25 ) + sum( 20 %<% labile$V1 %<% 25 ))) *100\n",
    "marmoset_conserved25_30kb = (sum( 25 %<% conserved$V1 %<% 30 )/(sum( 25 %<% conserved$V1 %<% 30 ) + sum( 25 %<% labile$V1 %<% 30 ))) *100\n",
    "marmoset_conserved>_30kb = (conserved$V1 %>% 30 )/(sum( conserved$V1 %>% 30  ) + sum( labile$V1 %>% 30  ))) *100\n",
    "\n",
    "\n",
    "# bushbaby\n",
    "conserved=read.csv('Conserved_bushbaby_distances.csv', header = F)\n",
    "labile=read.csv('Labile_bushbaby_distances.csv', header = F)\n",
    "\n",
    "bushbaby_conserved0kb = (sum( conserved$V1 == 0 )/(sum( conserved$V1 == 0 ) + sum( labile$V1 == 0  ))) *100\n",
    "bushbaby_conserved0_5kb = (sum( 0 %<% conserved$V1 %<% 5 )/(sum( 0 %<% conserved$V1 %<% 5 ) + sum( 0 %<% labile$V1 %<% 5 ))) *100\n",
    "bushbaby_conserved5_10kb = (sum( 5 %<% conserved$V1 %<% 10 )/(sum( 5 %<% conserved$V1 %<% 10 ) + sum( 5 %<% labile$V1 %<% 10 ))) *100\n",
    "bushbaby_conserved10_15kb = (sum( 10 %<% conserved$V1 %<% 15 )/(sum( 10 %<% conserved$V1 %<% 15 ) + sum( 10 %<% labile$V1 %<% 15 ))) *100\n",
    "bushbaby_conserved15_20kb = (sum( 15 %<% conserved$V1 %<% 20 )/(sum( 15 %<% conserved$V1 %<% 20 ) + sum( 15 %<% labile$V1 %<% 20 ))) *100\n",
    "bushbaby_conserved20_25kb = (sum( 20 %<% conserved$V1 %<% 25 )/(sum( 20 %<% conserved$V1 %<% 25 ) + sum( 20 %<% labile$V1 %<% 25 ))) *100\n",
    "bushbaby_conserved25_30kb = (sum( 25 %<% conserved$V1 %<% 30 )/(sum( 25 %<% conserved$V1 %<% 30 ) + sum( 25 %<% labile$V1 %<% 30 ))) *100\n",
    "bushbaby_conserved>_30kb = (conserved$V1 %>% 30 )/(sum( conserved$V1 %>% 30  ) + sum( labile$V1 %>% 30  ))) *100\n",
    "\n",
    "\n",
    "# mouse lemur\n",
    "conserved=read.csv('Conserved_mouse_lemur_distances.csv', header = F)\n",
    "labile=read.csv('Labile_mouse_lemur_distances.csv', header = F)\n",
    "\n",
    "mouse_lemur_conserved0kb = (sum( conserved$V1 == 0 )/(sum( conserved$V1 == 0 ) + sum( labile$V1 == 0  ))) *100\n",
    "mouse_lemur_conserved0_5kb = (sum( 0 %<% conserved$V1 %<% 5 )/(sum( 0 %<% conserved$V1 %<% 5 ) + sum( 0 %<% labile$V1 %<% 5 ))) *100\n",
    "mouse_lemur_conserved5_10kb = (sum( 5 %<% conserved$V1 %<% 10 )/(sum( 5 %<% conserved$V1 %<% 10 ) + sum( 5 %<% labile$V1 %<% 10 ))) *100\n",
    "mouse_lemur_conserved10_15kb = (sum( 10 %<% conserved$V1 %<% 15 )/(sum( 10 %<% conserved$V1 %<% 15 ) + sum( 10 %<% labile$V1 %<% 15 ))) *100\n",
    "mouse_lemur_conserved15_20kb = (sum( 15 %<% conserved$V1 %<% 20 )/(sum( 15 %<% conserved$V1 %<% 20 ) + sum( 15 %<% labile$V1 %<% 20 ))) *100\n",
    "mouse_lemur_conserved20_25kb = (sum( 20 %<% conserved$V1 %<% 25 )/(sum( 20 %<% conserved$V1 %<% 25 ) + sum( 20 %<% labile$V1 %<% 25 ))) *100\n",
    "mouse_lemur_conserved25_30kb = (sum( 25 %<% conserved$V1 %<% 30 )/(sum( 25 %<% conserved$V1 %<% 30 ) + sum( 25 %<% labile$V1 %<% 30 ))) *100\n",
    "mouse_lemur_conserved>_30kb = (conserved$V1 %>% 30 )/(sum( conserved$V1 %>% 30  ) + sum( labile$V1 %>% 30  ))) *100\n",
    "\n",
    "\n",
    "## Report them in the next single dataframe 'TSS_5Kb_WINDOWS_with_conserved_fractions.csv'\n",
    "\n",
    "\n",
    "#PLOT CONSERVATION FRACTION BY DISTANCE PER SPECIES\n",
    "TSS_DISTANCE = read.csv(\"TSS_5Kb_WINDOWS_with_conserved_fractions.csv\", header = T)\n",
    "TSS_DISTANCE$Distance_from_TSS <- factor(TSS_DISTANCE$Distance_from_TSS, levels=unique(TSS_DISTANCE$Distance_from_TSS))\n",
    "\n",
    "ggplot()+ \n",
    "  geom_line(aes_string(x='Distance_from_TSS',y='Fraction_conserved_chimp'), color='#ff8c00', data=TSS_DISTANCE, group =1, size = 2)+\n",
    "  geom_point(aes_string(x='Distance_from_TSS',y='Fraction_conserved_chimp'), color='#ff8c00',shape=19, size=5, data=TSS_DISTANCE)+\n",
    "  geom_line(aes_string(x='Distance_from_TSS',y='Fraction_conserved_rhesus'), color='#db7093', data=TSS_DISTANCE, group =1, size = 2)+\n",
    "  geom_point(aes_string(x='Distance_from_TSS',y='Fraction_conserved_rhesus'), color='#db7093',shape=19, size=5, data=TSS_DISTANCE)+\n",
    "  geom_line(aes_string(x='Distance_from_TSS',y='Fraction_conserved_marmoset'), color='#4169e1', data=TSS_DISTANCE, group =1, size = 2)+\n",
    "  geom_point(aes_string(x='Distance_from_TSS',y='Fraction_conserved_marmoset'), color='#4169e1',shape=19, size=5, data=TSS_DISTANCE)+\n",
    "  geom_line(aes_string(x='Distance_from_TSS',y='Fraction_conserved_bushbaby'), color='#00ced1', data=TSS_DISTANCE, group =1, size = 2)+\n",
    "  geom_point(aes_string(x='Distance_from_TSS',y='Fraction_conserved_bushbaby'), color='#00ced1',shape=19, size=5, data=TSS_DISTANCE)+\n",
    "  geom_line(aes_string(x='Distance_from_TSS',y='Fraction_conserved_mouse_lemur'), color='#0000cd', data=TSS_DISTANCE, group =1, size = 2)+\n",
    "  geom_point(aes_string(x='Distance_from_TSS',y='Fraction_conserved_mouse_lemur'), color='#0000cd',shape=19, size=5, data=TSS_DISTANCE)+\n",
    "  labs(x=\"\\nDISTANCE FROM TSS (Kb)\",y=\"FRACTION OF CONSERVED CREs (%)\\n\")+\n",
    "  theme_minimal()+\n",
    "  theme(axis.title=element_text(size=16), axis.text=element_text(size=20))\n",
    "\n",
    "\n",
    "######## Cell types: Figure 4c\n",
    "\n",
    "## From TABLES2.txt, extract CREs with available DHS data on cell types\n",
    "\n",
    "## In R\n",
    "\n",
    "matrix=read.table('TABLES2.txt', header = T)\n",
    "\n",
    "matrix=na.omit(matrix$cell_types_N)\n",
    "\n",
    "# Find quantiles\n",
    "q=quantile(matrix$cell_types_N, probs = seq(0, 1, 0.1), na.rm = FALSE)\n",
    "\n",
    "# Write quantiles in a dataframe\n",
    "write.csv(as.data.frame(q), file = 'quantiles_cell_types_N.csv', row.names = FALSE)\n",
    "\n",
    "# PLOT conserved fraction by cell type N\n",
    "cell_type = read.csv(\"conservation_cell_types.csv\", header = T)\n",
    "cell_type$N_cell_types <- factor(cell_type$N_cell_types, levels=unique(cell_type$N_cell_types))\n",
    "\n",
    "ggplot()+ \n",
    "  geom_line(aes_string(x='N_cell_types',y='Fraction_conserved'), color='#0073ff', data=cell_type, group =1, size =2)+\n",
    "  geom_point(aes_string(x='N_cell_types',y='Fraction_conserved'), color='#0073ff',shape=19, size=5, data=cell_type)+\n",
    "  labs(x=\"\\nNUMBER OF CELL TYPES\",y=\"FRACTION OF CONSERVED CREs (%)\\n\")+\n",
    "  theme_minimal()+\n",
    "  theme(axis.title=element_text(size=16), axis.text=element_text(size=20))\n",
    "\n",
    "\n",
    "### Quantify correlation between number of TFBSs and degree of conservation\n",
    "\n",
    "# In matrix$conservation_status replace \"conserved\" with \"0' and all of the other states with \"1\"\n",
    "# Then quantify correlation with a linear regression\n",
    "corr = lm(conserved ~ n_cell_types, data=matrix)\n",
    "summary(corr)\n",
    "\n",
    "\n",
    "######## TFBS: Figure 4d\n",
    "\n",
    "## From TABLES2.txt, extract CREs with available DHS data on TFBS in HepG2 cells\n",
    "\n",
    "## In R\n",
    "\n",
    "matrix=read.table('TABLES2.txt', header = T)\n",
    "matrix=na.omit(matrix$TFBS_N)\n",
    "\n",
    "# Find quantiles\n",
    "q=quantile(matrix$TFBS_N, probs = seq(0, 1, 0.15), na.rm = FALSE)\n",
    "\n",
    "# Write quantiles in a dataframe\n",
    "write.csv(as.data.frame(q), file = 'quantiles_TFBS_N.csv', row.names = FALSE)\n",
    "\n",
    "# Count how many conserved and labile CREs within each quantile, compute conserved fraction and write data into a single dataframe 'conservation_TFBS.csv'\n",
    "\n",
    "\n",
    "\n",
    "# PLOT conserved fraction by cell type N\n",
    "\n",
    "TFBS = read.csv(\"conservation_TFBS.csv\", header = T)\n",
    "TFBS$N_TFBSs <- factor(TFBS$N_TFBSs, levels=unique(TFBS$N_TFBSs))\n",
    "\n",
    "ggplot()+ \n",
    "  geom_line(aes_string(x='N_TFBSs',y='Fraction_conserved'), color='#0073ff', data=TFBS, group =1, size =2)+\n",
    "  geom_point(aes_string(x='N_TFBSs',y='Fraction_conserved'), color='#0073ff',shape=19, size=5, data=TFBS)+\n",
    "  labs(x=\"\\nNUMBER OF TFBS\",y=\"FRACTION OF CONSERVED CREs (%)\\n\")+\n",
    "  theme_minimal()+\n",
    "  theme(axis.title=element_text(size=16), axis.text=element_text(size=20))\n",
    "  \n",
    "\n",
    "\n",
    "### Quantify correlation between number of TFBSs and degree of conservation\n",
    "\n",
    "# In matrix$conservation_status replace \"conserved\" with \"0' and all of the other states with \"1\"\n",
    "# Then quantify correlation with a linear regression\n",
    "corr = lm(conservation_status ~ TFBS_N, data=matrix)\n",
    "summary(corr)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TE analysis and replication data comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "\n",
    "#############################################\n",
    "###SVAs analysis\n",
    "\n",
    "## In humans, compare SVA that evolved into TEs with SVAs that did not\n",
    "\n",
    "# From the repeat mask extract the SVAs bedfile\n",
    "cat GRCh38_repeat_mask.bed | grep \"SVA\" > GRCh38_SVAs.bed\n",
    "\n",
    "# Intersect the SVA bed file with all of the human peaks, including the ones that do not have orthologs in primates, using an overlap threshold of 25% of the length\n",
    "bedtools intersect -a GRCh38_SVAs.bed -b all_human_peaks.bed  -F 0.25 -wa -wb > SVA_exapted.bed\n",
    "bedtools intersect -a GRCh38_SVAs.bed -b all_human_peaks.bed  -F 0.25 -wa -wb -v > SVA_NOT_exapted.bed\n",
    "\n",
    "# Annotate SVA_exapted.bed and SVA_NOT_exapted.bed\n",
    "\n",
    "# Closest genes, TSS distance, strand\n",
    "bedtools closest -a SVA_exapted.bed -b GRCh38_TSSs.bed > SVA_exapted_annotated.bed\n",
    "bedtools closest -a SVA_NOT_exapted.bed -b GRCh38_TSSs.bed > SVA_NOT_exapted_annotated.bed\n",
    "\n",
    "#Add DHS data and HepG2 TFBS data \n",
    "bedtools intersect -a SVA_exapted_annotated.bed -b ENCODE_DHS_DATA.bed > SVA_exapted_annotated_DHS.bed\n",
    "bedtools intersect -a SVA_NOT_exapted_annotated.bed -b ENCODE_DHS_DATA.bed > SVA_NOT_exapted_annotated_DHS.bed\n",
    "\n",
    "bedtools intersect -a SVA_exapted_annotated_DHS.bed -b ENCODE_TFBS_DATA.bed > SVA_exapted_annotated_DHS_TFBS.bed\n",
    "bedtools intersect -a SVA_NOT_exapted_annotated_DHS.bed -b ENCODE_TFBS_DATA.bed > SVA_NOT_exapted_annotated_DHS_TFBS.bed\n",
    "\n",
    "\n",
    "###############\n",
    "## eRNAs analyses\n",
    "\n",
    "# From tableS2 extract conserved and labile CREs\n",
    "cat TABLE2.txt | grep \"conserved\"  > conserved_CREs.txt\n",
    "cat TABLE2.txt | grep -e \"human_specific\" -e \"apes_specific\" -e \"other_recently_evolved\"  > recently_evolved_CREs.txt\n",
    "\n",
    "# Save them as bedfiles, then look for overlap, WITHIN +/- 1 kb, with transcribed eRNAs (permissive set from FANTO5 consortium, after liftovering them to GRCh38 system)\n",
    "bedtools window -w 1000 -a conserved_CREs.bed -b permissive_enhancers_hg38.bed > conserved_transcribed_1kb.txt\n",
    "bedtools window -w 1000 -a ecently_evolved_CREs.bed -b permissive_enhancers_hg38.bed > labile_transcribed_1kb.txt\n",
    "\n",
    "\n",
    "#################################################################################\n",
    "############# Comparison with Villar et al. (2015) data\n",
    "\n",
    "### Replicated human peaks\n",
    "\n",
    "# Using bedtools \"window\", overlap our human H3K27Ac peaks with Villar et al (2015) human H3K27Ac peaks, after liftovering their peak coordinates to GRCh38 system\n",
    "# window of overlap = 1kb to find replicated H3K27Ac peaks\n",
    "bedtools window -a Villar_human_H3K27Ac.bed -b our_human_H3K27Ac.bed -w 1000 > replicated_human_H3K27Ac_peaks.bed\n",
    "bedtools window -a Villar_human_H3K27Ac.bed -b our_human_H3K27Ac.bed -w 1000 -v > NOT_replicated_human_H3K27Ac_peaks.bed\n",
    "\n",
    "\n",
    "# Annotate replicated and not replicated peaks \n",
    "\n",
    "# Closest genes, TSS distance, strand\n",
    "bedtools closest -a replicated_human_H3K27Ac_peaks.bed -b GRCh38_TSSs.bed > replicated_human_H3K27Ac_peaks_annotated.bed\n",
    "bedtools closest -a NOT_replicated_human_H3K27Ac_peaks.bed -b GRCh38_TSSs.bed > NOT_replicated_human_H3K27Ac_peaks_annotated.bed\n",
    "\n",
    "#Add DHS data and HepG2 TFBS data \n",
    "bedtools intersect -a replicated_human_H3K27Ac_peaks_annotated.bed -b ENCODE_DHS_DATA.bed > replicated_human_H3K27Ac_peaks_annotated_DHS.bed\n",
    "bedtools intersect -a NOT_replicated_human_H3K27Ac_peaks_annotated.bed -b ENCODE_DHS_DATA.bed > NOT_replicated_human_H3K27Ac_peaks_annotated_DHS.bed\n",
    "\n",
    "bedtools intersect -a replicated_human_H3K27Ac_peaks_annotated_DHS.bed -b ENCODE_TFBS_DATA.bed > replicated_human_H3K27Ac_peaks_annotated_DHS_TFBS.bed\n",
    "bedtools intersect -a NOT_replicated_human_H3K27Ac_peaks_annotated_DHS.bed > NOT_replicated_human_H3K27Ac_peaks_annotated_DHS_TFBS.bed\n",
    "\n",
    "\n",
    "### Opossum analysis\n",
    "\n",
    "# After liftovering opossum peaks (Villar et al., 2015) to GRCh38 coordinates use bedtools to see how many of the 47,643 human consensus CREs having orthologs in other primates (i.e. TABLES2), also have orthologs in opossum\n",
    "bedtools intersect -a TABLES2.bed -b opossum_peaks.bed -wa > human_opossum_orthologs.bed\n",
    "\n",
    "# Count how many of of the human-opossum orthologs are primate conserved CREs, and save them in a file\n",
    "cat human_opossum_orthologs.bed | grep \"conserved\" | wc -l\n",
    "cat human_opossum_orthologs.bed | grep \"conserved\" > human_opossum_orthologs_conserved.txt\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
